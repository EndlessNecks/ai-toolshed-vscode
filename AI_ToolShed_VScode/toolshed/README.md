\# ğŸ› ï¸ AI Tool Shed  

\### Local RAG â€¢ Codestral â€¢ ChromaDB â€¢ VS Code (Continue) Integration  



Give your AI full, live access to your codebase.



<div align="center">



!\[GitHub last commit](https://img.shields.io/github/last-commit/yourname/AI\_ToolShed?color=blue)

!\[GitHub issues](https://img.shields.io/github/issues/yourname/AI\_ToolShed)

!\[License](https://img.shields.io/badge/license-MIT-green.svg)

!\[PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

!\[Python Version](https://img.shields.io/badge/python-3.10%2B-yellow.svg)



</div>



---



\# ğŸ“š Overview



The \*\*AI Tool Shed\*\* is a modular, open-source framework that gives an LLM (such as Codestral) \*\*true visibility into your entire codebase\*\*, allowing it to:



\- read your project  

\- retrieve relevant files on demand  

\- suggest changes with accurate file/line references  

\- automatically rebuild its own vector knowledge base on save  

\- integrate seamlessly with \*\*Continue\*\* inside \*\*VS Code\*\*  



Think of it as your own \*\*local GitHub Copilot Enterprise\*\*, but fully under your control.



---



\# ğŸ”§ Core Features



\- âœ”ï¸ Local RAG engine (chunk â†’ embed â†’ index â†’ retrieve)

\- âœ”ï¸ Persistent ChromaDB vector store

\- âœ”ï¸ Watchdog-powered live reindexing

\- âœ”ï¸ Continue (VS Code) two-way communication

\- âœ”ï¸ Codestral orchestration system

\- âœ”ï¸ OpenAI-compatible API client

\- âœ”ï¸ Modular, extensible architecture

\- âœ”ï¸ Fully open-source \& privacy-friendly



---



\# ğŸ—ï¸ Architecture



&nbsp;     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;     â”‚     VS Code        â”‚

&nbsp;     â”‚    (Continue)      â”‚

&nbsp;     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

&nbsp;               â”‚ model\_config

&nbsp;               â–¼

&nbsp;   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;   â”‚  codestral\_binding.py       â”‚

&nbsp;   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

&nbsp;             â”‚ creates

&nbsp;             â–¼

&nbsp;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;â”‚  Codestral Orchestrator      â”‚

&nbsp;â”‚  â€¢ builds prompts            â”‚

&nbsp;â”‚  â€¢ injects RAG context       â”‚

&nbsp;â”‚  â€¢ handles system directives â”‚

&nbsp;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

&nbsp;             â”‚ calls

&nbsp;             â–¼

&nbsp;   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;   â”‚       Retriever        â”‚

&nbsp;   â”‚  â€¢ query embeddings    â”‚

&nbsp;   â”‚  â€¢ Chroma similarity   â”‚

&nbsp;   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

&nbsp;                â”‚ reads/writes

&nbsp;   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;   â”‚      Chroma Vector Store       â”‚

&nbsp;   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

&nbsp;                â–²

&nbsp;                â”‚ writes

&nbsp;   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

&nbsp;   â”‚           Indexer              â”‚

&nbsp;   â”‚       (rerun on save)          â”‚

&nbsp;   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



---



\# ğŸ“ Project Structure



AI\_ToolShed/

â”‚

â”œâ”€â”€ configs/

â”‚ â”œâ”€â”€ paths.json

â”‚ â”œâ”€â”€ rag\_config.json

â”‚

â”œâ”€â”€ rag\_engine/

â”‚ â”œâ”€â”€ chunker.py

â”‚ â”œâ”€â”€ embedder.py

â”‚ â”œâ”€â”€ indexer.py

â”‚ â”œâ”€â”€ retriever.py

â”‚

â”œâ”€â”€ vector\_db/

â”‚ â””â”€â”€ chroma/

â”‚

â”œâ”€â”€ glue\_continue/

â”‚ â”œâ”€â”€ codestral\_binding.py

â”‚ â”œâ”€â”€ vscode\_hooks.py

â”‚

â”œâ”€â”€ orchestration/

â”‚ â”œâ”€â”€ codestral\_client.py

â”‚ â”œâ”€â”€ codestral\_orchestrator.py

â”‚

â”œâ”€â”€ project\_watchers/

â”‚ â”œâ”€â”€ watcher.py

â”‚

â”œâ”€â”€ logs/

â”‚

â”œâ”€â”€ tests/

â”‚ â”œâ”€â”€ test\_embedding.py

â”‚ â”œâ”€â”€ test\_retrieval.py

â”‚

â”œâ”€â”€ setup.bat

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md



---



\# ğŸš€ Setup Instructions  

\*(Python 3.14 is the required version)\*



\## 1. Install dependencies



\### Windows

```bash

py -3.14 -m pip install -r requirements.txt


Linux / macOS



Ensure Python 3.14 is installed (via pyenv, source build, etc.):



python3.14 -m pip install -r requirements.txt


2\. Build the initial RAG index

python3.14 rag\_engine/indexer.py


3. Start the auto-index watcher

python3.14 project\_watchers/watcher.py





Automatically rebuilds your vector store whenever you save files.

4. Configure Continue (VS Code)



Add to your Continue config.yaml:



models:

&nbsp; - id: codestral

&nbsp;   provider: openai

&nbsp;   api\_base: "http://localhost:11434/v1"

&nbsp;   model: "codestral-latest"

&nbsp;   api\_key: ""

&nbsp;   max\_tokens: 4096

&nbsp;   temperature: 0.2



python:

&nbsp; scripts:

&nbsp;   onModelLoad: "D:/AI\_Workspace/AI\_ToolShed/glue\_continue/vscode\_hooks.py:on\_model\_loaded"

&nbsp;   onUserMessage: "D:/AI\_Workspace/AI\_ToolShed/glue\_continue/vscode\_hooks.py:handle\_user\_query"



ğŸ¤– Usage (Inside VS Code)



Ask Continue:



"Explain how X works"

"Where is Y implemented?"

"Refactor Z for clarity"

"Find API calls to function foo()"





The pipeline:



Retrieves relevant code



Injects it into the system prompt



Sends it to Codestral



Returns a structured answer with file + line references



ğŸ§ª Testing

python3.14 -m unittest discover -s tests





Tests include:



test\_embedding.py â€” embedding normalization \& structure



test\_retrieval.py â€” uses a temporary in-memory Chroma instance



ğŸ”§ Developer Scripts



Rebuild index:



python3.14 rag\_engine/indexer.py





Clear logs:



rm logs/\*.log        # Linux

del logs\\\*.log       # Windows





Start watcher:



python3.14 project\_watchers/watcher.py



ğŸ“¦ Dependencies

chromadb

watchdog

numpy

tqdm

requests





Compatible with any model served over an OpenAI-compatible API (local or remote).

